{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pem82y_88n7K"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mar8dDRINAuk"
      },
      "source": [
        "\n",
        "## Set Global Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VG-tmnjDHJgr"
      },
      "outputs": [],
      "source": [
        "# set system\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "ABDUL_G_DRIVE = False\n",
        "\n",
        "# set torch device\n",
        "import torch \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHk3pCsSNXnd"
      },
      "source": [
        "## Initialize Colab:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQXFm71QOTRP"
      },
      "source": [
        "### Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZTcdMFXVtMN",
        "outputId": "def30875-2375-4825-b743-3621647bcb5f"
      },
      "outputs": [],
      "source": [
        "# connect to drive\n",
        "if IN_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "  # set project path from drive\n",
        "  if ABDUL_G_DRIVE:\n",
        "    project_path = \"/content/gdrive/MyDrive/00 Projects/AML\"\n",
        "    %cd -q $project_path \n",
        "    !pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MKW9Pf3N4hL"
      },
      "source": [
        "### Install PyG in Colab "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e948Qm5iLAKK",
        "outputId": "5abb9b6a-88ba-4f51-ea98-adc6e5b6880a"
      },
      "outputs": [],
      "source": [
        "# define dynamic function to install pyg\n",
        "def install_pyg():\n",
        "    try:\n",
        "        import torch_geometric\n",
        "    except:\n",
        "        TORCH = torch.__version__.split('+')[0]\n",
        "        CUDA = 'cu' + torch.version.cuda.replace('.', '')\n",
        "        !pip install torch-scatter     -q -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "        !pip install torch-sparse      -q -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "        !pip install torch-cluster     -q -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "        !pip install torch-spline-conv -q -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "        !pip install torch-geometric   -q\n",
        "\n",
        "# install\n",
        "if IN_COLAB: install_pyg()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1Q3lQ4jOoAt"
      },
      "source": [
        "## Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-StflntjuCWd"
      },
      "outputs": [],
      "source": [
        "# src \n",
        "from models import MLP, GCN, GAT\n",
        "from random_split import random_split\n",
        "from p_reg_loss import A_hat_computations, p_reg_loss\n",
        "from lap_loss import lap_loss\n",
        "from cp_loss import cp_loss\n",
        "from helper import visualize_Atlas, visualize_TSNE, visualize_CM, print_dataset, print_data\n",
        "from utils import report_vis\n",
        "from utils import report_stats\n",
        "\n",
        "from evaluate_model import acc, icd0, icd1, icd2, icd3, icd4\n",
        "\n",
        "# packages\n",
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW5eN_FL8iVk"
      },
      "source": [
        "# Train, Test and Evaluation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5fcJFQlNmDU"
      },
      "source": [
        "### Train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2IrYVnKdTpoe"
      },
      "outputs": [],
      "source": [
        "# Train func\n",
        "def train(model, optimizer, criterion, data, train_mask, mu, p_reg_dict=None):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()  # Clear gradients.\n",
        "    _, Z = model(data)     # Perform a single forward pass.    \n",
        "    loss_1 = criterion(Z[train_mask], data.y[train_mask])  # Compute the loss solely based on the training nodes.\n",
        "    loss_2 = 0\n",
        "    if mu >0:\n",
        "        loss_2 = p_reg_loss(Z, \n",
        "                          p_reg_dict['A_hat'], \n",
        "                          p_reg_dict['A_hat_mask'], \n",
        "                          p_reg_dict['N'], \n",
        "                          phi = p_reg_dict['phi'])\n",
        "    loss = loss_1 + mu * loss_2      \n",
        "    loss.backward()  # Derive gradients.\n",
        "    optimizer.step()  # Update parameters based on gradients.\n",
        "    return loss, Z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRwMz3D_O9vA"
      },
      "source": [
        "## Test Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MTvjA2gPPCwi"
      },
      "outputs": [],
      "source": [
        "# Test func: Using the early stopping method\n",
        "def test(model, data, mask, criterion, mu, p_reg_dict):\n",
        "    # eval\n",
        "    model.eval()\n",
        "    _, Z = model(data)\n",
        "\n",
        "    # cal loss\n",
        "    loss_1 = criterion(Z[mask], data.y[mask])  # Compute the loss solely based on the training nodes.\n",
        "    loss_2 = 0\n",
        "    #print(\"Test p_reg_dict is None\", (p_reg_dict is None))\n",
        "    if p_reg_dict is not None:\n",
        "        loss_2 = p_reg_loss(Z,\n",
        "                            p_reg_dict['A_hat'],\n",
        "                            p_reg_dict['A_hat_mask'],\n",
        "                            p_reg_dict['N'],\n",
        "                            phi = p_reg_dict['phi'])\n",
        "    loss = loss_1 + mu * loss_2      \n",
        "\n",
        "    # cal metrics\n",
        "    y_pred = Z.argmax(dim=1)  # Use the class with highest probability.\n",
        "    acc = accuracy_score    (y_true = data.y[mask].cpu().detach().numpy(), y_pred  = y_pred[mask].cpu().detach().numpy())\n",
        "    \n",
        "    return loss, Z, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wtj4yOoFuhR"
      },
      "source": [
        "# Average intra-class distance\n",
        "\n",
        "see 4.2.3 - **Empirical verification** for definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LlI50Y0pFuhS"
      },
      "outputs": [],
      "source": [
        "def intra_class_distance(out, data, nb_classes, softmax=True):\n",
        "\n",
        "    m = torch.nn.Softmax(dim=0)\n",
        "    \n",
        "    out = out[data.test_mask] # try other masks or none\n",
        "    pred = out.cpu().argmax(dim=1)\n",
        "    N = len(pred)\n",
        "    #print(N)\n",
        "    w=0\n",
        "    pred = pred.cpu()\n",
        "    classes = np.unique(pred.cpu())\n",
        "    print(\"classes:\", classes)\n",
        "    missing_classes = list(set(range(0,nb_classes)) - set(classes))\n",
        "\n",
        "    if len(missing_classes)>0:\n",
        "        print('classes {} are missing'.format(missing_classes))\n",
        "        \n",
        "    for cl in classes:\n",
        "        # Sk = nodes in class k\n",
        "        Sk = (pred == cl).nonzero(as_tuple=True)[0]\n",
        "        # Compute ck\n",
        "        ck = torch.Tensor(np.zeros(len(classes)))\n",
        "        ck = ck.to(device)\n",
        "        #print(ck.size())\n",
        "        for i in Sk:\n",
        "            #zi = torch.max(out[i]).item()\n",
        "            zi = out[i].clone().detach()\n",
        "            zi = torch.Tensor([zi[j] for j in classes])\n",
        "            if softmax:\n",
        "              zi = m(zi)\n",
        "            zi = zi.to(device)\n",
        "            ck += zi\n",
        "        ck = ck/len(Sk)\n",
        "        ck = ck.to(device)\n",
        "\n",
        "        for i in Sk:\n",
        "            #zi = torch.max(out[i]).item()\n",
        "            zi = out[i].clone().detach()\n",
        "            zi = torch.Tensor([zi[j] for j in classes])\n",
        "            if softmax:\n",
        "              zi = m(zi)\n",
        "            zi = zi.to(device)\n",
        "            w += torch.linalg.norm(zi-ck)\n",
        "        \n",
        "        #print(clk, ck, w)\n",
        "\n",
        "    return w/N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb0irwn0PJo7"
      },
      "source": [
        "## Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "elGSgTWcTtyA"
      },
      "outputs": [],
      "source": [
        "def evaluation( A = None, # int \n",
        "                B = None, # int \n",
        "                mu = None, # float \n",
        "                seed = None, # float \n",
        "                As = None, # int list \n",
        "                Bs = None, # int list \n",
        "                mus = None, # float list \n",
        "                seeds = None, # float list \n",
        "                reg_loss = None, # str: 'p_reg', 'lap_reg', 'cp_reg', 'no_reg' \n",
        "                p_reg_phi = 'cross_entropy', # str: 'cross_entropy', 'squared_error', 'kl_divergence' #####################\n",
        "                datasets = ['Cora'], # str list\n",
        "                epochs = 200, # int\n",
        "                verbose = True # boolean\n",
        "                ):\n",
        "\n",
        "    # check A and B arg.\n",
        "    if (A is not None) | (B is not None):\n",
        "        assert A is not None, \"A is missing\" \n",
        "        assert B is not None, \"B is missing\" \n",
        "        assert (seed is not None) | (seeds is not None), \"seed or seeds is missing\"\n",
        "        assert As is None, \"As should not be given\"\n",
        "        assert Bs is None, \"Bs should not be given\"\n",
        "\n",
        "    # check mu input arg.\n",
        "    if mu is not None:\n",
        "        if mu == 0:\n",
        "            assert reg_loss == 'no_reg', \"reg_loss should be 'no_reg'\"\n",
        "\n",
        "    # check seed input arg.\n",
        "    if seed is not None: \n",
        "        assert seeds is None, \"seeds should not be given\"\n",
        "\n",
        "    # check lists input args\n",
        "    if mus is not None:\n",
        "        assert mu is None, \"mu should not be given\"\n",
        "        params, params_len, params_tag = mus, len(mus), 'Mus'\n",
        "        if verbose: print(f'Training with {reg_loss} with different \"Mus\":')\n",
        "\n",
        "    elif seeds is not None:\n",
        "        assert seed is None, \"seed should not be given\"\n",
        "        params, params_len, params_tag = seeds, len(seeds), 'Seeds'\n",
        "        if verbose: print(f'Training with {reg_loss} with different \"Seeds\":')\n",
        "\n",
        "    elif (As is not None) | (Bs is not None): \n",
        "        assert seed is not None, \"seed is missing\" \n",
        "        assert As is not None, \"As are missing\"\n",
        "        assert Bs is not None, \"Bs are missing\"\n",
        "        assert len(As) == len (Bs), \"As and Bs do not have the same length\" \n",
        "        assert A is None, \"A should not be given\"\n",
        "        assert B is None, \"B should not be given\"\n",
        "        params, params_len, params_tag = As, len(As),'Training Nodes'\n",
        "        if verbose: print(f'Training with {reg_loss} with different \"Number Training Nodes\":')\n",
        "\n",
        "    else:\n",
        "        params, params_len, params_tag = [], 1, 'No Params Loop'\n",
        "        if verbose: print(f'Training with {reg_loss} with {params_tag}')\n",
        "        assert (mu is not None) & (reg_loss is not None), 'mu and reg_loss are missing' \n",
        "\n",
        "\n",
        "    # evaluation Storage\n",
        "    Results = {}\n",
        "    metrics = []\n",
        "    \n",
        "    # loop over datasets\n",
        "    for dataset_name in datasets: \n",
        "        # define dataset\n",
        "        if verbose: print(f'=========================\\n{dataset_name}:')\n",
        "        if dataset_name == 'Cora':\n",
        "            nb_classes = 7\n",
        "            if ABDUL_G_DRIVE: dataset = Planetoid(root=f'data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "            else: dataset = Planetoid(root=f'/tmp/Cora', name='Cora', transform=NormalizeFeatures())\n",
        "        elif dataset_name == 'CiteSeer':\n",
        "            nb_classes = 6\n",
        "            if ABDUL_G_DRIVE: dataset = Planetoid(root=f'data/Planetoid', name='CiteSeer', transform=NormalizeFeatures())\n",
        "            else: dataset = Planetoid(root=f'/tmp/CiteSeer', name='CiteSeer', transform=NormalizeFeatures())\n",
        "        elif dataset_name == 'PubMed':\n",
        "            nb_classes = 3\n",
        "            if ABDUL_G_DRIVE: dataset = Planetoid(root=f'data/Planetoid', name='PubMed', transform=NormalizeFeatures())         \n",
        "            else: dataset = Planetoid(root=f'/tmp/PubMed', name='PubMed', transform=NormalizeFeatures())         \n",
        "        else:\n",
        "            raise NotImplementedError('Only Cora, CiteSeer and PubMed datasets are supported')\n",
        "        \n",
        "        # define data\n",
        "        data = dataset[0]\n",
        "        data = data.to(device)\n",
        "\n",
        "        # calc split here when params_tag == 'Mus' or 'No Params Loop':\n",
        "        if (params_tag == 'Mus') | (params_tag == 'No Params Loop'):\n",
        "            if (seed is not None) & (A is not None) & (B is not None):\n",
        "                train_mask, val_mask, test_mask = random_split(dataset, A, B, seed)\n",
        "            else:\n",
        "                train_mask, val_mask, test_mask = data.train_mask, data.val_mask, data.test_mask\n",
        "\n",
        "        # Calculate A_hat as it's training invariant \n",
        "        if mus is not None or mu>0:\n",
        "            A_hat, A_hat_mask, N = A_hat_computations(data)\n",
        "            p_reg_dict = {'A_hat': A_hat, \n",
        "                          'A_hat_mask': A_hat_mask, \n",
        "                          'N': N, \n",
        "                          'phi': 'cross_entropy' if p_reg_phi is None else p_reg_phi}  \n",
        "        else: \n",
        "            p_reg_dict = None\n",
        "        \n",
        "        #print(\"p_reg_dict\",p_reg_dict)\n",
        "\n",
        "        # define test evaluation metrices\n",
        "        Results[dataset_name+'_acc' ] = []\n",
        "        Results[dataset_name+'_loss'] = []\n",
        "        Results[dataset_name+'_Z'   ] = []\n",
        "        Results[dataset_name+'_y'   ] = []\n",
        "        Results[dataset_name+'_icd' ] = []\n",
        "\n",
        "        # loop over params\n",
        "        for i in range(params_len):\n",
        "            # define model parameters        \n",
        "            if params_tag == 'Mus': \n",
        "                mu = mus[i]\n",
        "            elif params_tag == 'Seeds': \n",
        "                seed = seeds[i]\n",
        "                # calc the split\n",
        "                if (A is not None) & (B is not None):\n",
        "                    train_mask, val_mask, test_mask = random_split(dataset, A, B, seed)\n",
        "                else:\n",
        "                    train_mask, val_mask, test_mask = data.train_mask, data.val_mask, data.test_mask\n",
        "            elif params_tag == 'Training Nodes': \n",
        "                A, B = As[i], Bs[i]\n",
        "                # calc the split\n",
        "                if seed is not None:\n",
        "                    train_mask, val_mask, test_mask = random_split(dataset, A, B, seed)\n",
        "                else:\n",
        "                    train_mask, val_mask, test_mask = data.train_mask, data.val_mask, data.test_mask\n",
        "\n",
        "\n",
        "            # define MOC\n",
        "            model = GCN(dataset,\n",
        "                        hidden_channels=64, \n",
        "                        seed = 0 if seed is None else seed).to(device)\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "            # loop over epochs\n",
        "            Val_Loss = np.inf\n",
        "            for epoch in range(epochs):\n",
        "                # train\n",
        "                train(model, optimizer, criterion, data, train_mask, mu, p_reg_dict)    \n",
        "                \"\"\"# test\n",
        "                with torch.no_grad():\n",
        "                  #print(\"Eval1 p_reg_dict is None\", (p_reg_dict is None))\n",
        "                  val_loss , _ , _  = test(model, data, val_mask, criterion, mu, p_reg_dict)\n",
        "                  if (val_loss < Val_Loss):\n",
        "                      #print(\"Eval2 p_reg_dict is None\", (p_reg_dict is None))\n",
        "                      test_loss, test_Z, test_acc = test(model, data, test_mask, criterion, mu, p_reg_dict)\n",
        "            \"\"\"\n",
        "\n",
        "            train_acc, val_acc, test_acc = acc(model, data)\n",
        "            \n",
        "            d0 = icd0(model, data)\n",
        "            d1 = icd1(model, data)\n",
        "            d2 = icd2(model, data)\n",
        "            d3 = icd3(model, data)\n",
        "            d4 = icd4(model, data)\n",
        "\n",
        "            metrics.append({\n",
        "            'mu': mu, \n",
        "            'seed': seed,\n",
        "            'train_acc': np.round(train_acc,4), \n",
        "            'val_acc': np.round(val_acc,4), \n",
        "            'test_acc': np.round(test_acc,4),\n",
        "            'icd0': d0,\n",
        "            'icd1': d1,\n",
        "            'icd2': d2,\n",
        "            'icd3': d3,\n",
        "            'icd4_train': d4[0],\n",
        "            'icd4_val': d4[1],\n",
        "            'icd4_test': d4[2],\n",
        "            })\n",
        "\n",
        "            print(metrics[-1])\n",
        "            \n",
        "            out = model(data)[1] # or [0]???\n",
        "            icd = intra_class_distance(out, data, nb_classes, softmax=True)\n",
        "\n",
        "            # save test metrices, loss and embadding  \n",
        "            Results[dataset_name+'_y'   ].append(None)\n",
        "            Results[dataset_name+'_icd' ].append(icd.item())\n",
        "            \n",
        "            print(f'    Icd: {icd:.4f}')\n",
        "\n",
        "\n",
        "    return Results, params, params_tag, reg_loss, metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmNqR7C5PweY"
      },
      "source": [
        "## Clear variable Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ITh4d-cXPzGJ"
      },
      "outputs": [],
      "source": [
        "def clear():\n",
        "    # clear varibles\n",
        "    global A, B, mu, seed  \n",
        "    global As, Bs, mus, seeds \n",
        "    global reg_loss, p_reg_phi\n",
        "    global epochs, datasets, verbose\n",
        "    A = None\n",
        "    B = None  \n",
        "    mu = None  \n",
        "    seed = None  \n",
        "    As = None \n",
        "    Bs = None  \n",
        "    mus = None  \n",
        "    seeds = None  \n",
        "    reg_loss = None \n",
        "    p_reg_phi = None \n",
        "    epochs = 200\n",
        "    datasets = ['Cora', 'CiteSeer', 'PubMed']\n",
        "    verbose = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s3NzrWwMILD"
      },
      "source": [
        "## With P-reg:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK1YgJNHRX1c"
      },
      "source": [
        "#### Original split different Mus \n",
        "L03 P02 Q01\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WqktR8KB1E-5"
      },
      "outputs": [],
      "source": [
        "# set parameters\n",
        "clear()\n",
        "reg_loss='p_reg'\n",
        "p_reg_phi = 'cross_entropy'\n",
        "mus = np.linspace(0,2,21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIZuO_fAvr0E",
        "outputId": "775e12c7-aaa8-46b0-f410-fef41a61106f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with p_reg with different \"Mus\":\n",
            "=========================\n",
            "Cora:\n",
            "{'mu': 0.0, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.788, 'test_acc': 0.807, 'icd0': tensor(0.2261), 'icd1': 1.9104216, 'icd2': 9.207906e-05, 'icd3': 0.9886758, 'icd4_train': 0.0017158272, 'icd4_val': 0.0011232726, 'icd4_test': 0.00025149793}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.2261\n",
            "{'mu': 0.1, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.796, 'test_acc': 0.816, 'icd0': tensor(0.2136), 'icd1': 2.4627101, 'icd2': 0.000136518, 'icd3': 1.1279376, 'icd4_train': 0.0022102278, 'icd4_val': 0.001480335, 'icd4_test': 0.00038342882}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.2136\n",
            "{'mu': 0.2, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.808, 'test_acc': 0.825, 'icd0': tensor(0.1992), 'icd1': 3.0508316, 'icd2': 0.00018949682, 'icd3': 1.2586855, 'icd4_train': 0.0027481436, 'icd4_val': 0.0018546826, 'icd4_test': 0.0005597907}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1992\n",
            "{'mu': 0.30000000000000004, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.822, 'test_acc': 0.829, 'icd0': tensor(0.1846), 'icd1': 3.6095834, 'icd2': 0.0002475959, 'icd3': 1.3702339, 'icd4_train': 0.0032760054, 'icd4_val': 0.0022320792, 'icd4_test': 0.00075925636}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1846\n",
            "{'mu': 0.4, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.816, 'test_acc': 0.832, 'icd0': tensor(0.1718), 'icd1': 4.11422, 'icd2': 0.00030619345, 'icd3': 1.4627507, 'icd4_train': 0.0037627278, 'icd4_val': 0.0026317718, 'icd4_test': 0.00096057885}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1718\n",
            "{'mu': 0.5, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.812, 'test_acc': 0.838, 'icd0': tensor(0.1610), 'icd1': 4.568936, 'icd2': 0.00035733116, 'icd3': 1.5408174, 'icd4_train': 0.00420994, 'icd4_val': 0.0029721337, 'icd4_test': 0.0011290016}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1610\n",
            "{'mu': 0.6000000000000001, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.808, 'test_acc': 0.838, 'icd0': tensor(0.1516), 'icd1': 4.979502, 'icd2': 0.00040283686, 'icd3': 1.6081303, 'icd4_train': 0.004605706, 'icd4_val': 0.0032651175, 'icd4_test': 0.0012575292}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1516\n",
            "{'mu': 0.7000000000000001, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.802, 'test_acc': 0.84, 'icd0': tensor(0.1433), 'icd1': 5.352482, 'icd2': 0.0004476002, 'icd3': 1.666633, 'icd4_train': 0.0049751764, 'icd4_val': 0.0035327624, 'icd4_test': 0.0013833955}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1433\n",
            "{'mu': 0.8, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.8, 'test_acc': 0.838, 'icd0': tensor(0.1376), 'icd1': 5.6836286, 'icd2': 0.0004891769, 'icd3': 1.7166246, 'icd4_train': 0.0052995523, 'icd4_val': 0.0037373204, 'icd4_test': 0.0014958156}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1376\n",
            "{'mu': 0.9, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.796, 'test_acc': 0.836, 'icd0': tensor(0.1313), 'icd1': 5.9931755, 'icd2': 0.00051759375, 'icd3': 1.7616514, 'icd4_train': 0.0055632964, 'icd4_val': 0.0038964818, 'icd4_test': 0.0015816045}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1313\n",
            "{'mu': 1.0, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.8, 'test_acc': 0.833, 'icd0': tensor(0.1253), 'icd1': 6.3295636, 'icd2': 0.0005414293, 'icd3': 1.804424, 'icd4_train': 0.0060127275, 'icd4_val': 0.004087381, 'icd4_test': 0.0016542779}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1253\n",
            "{'mu': 1.1, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.802, 'test_acc': 0.827, 'icd0': tensor(0.1205), 'icd1': 6.5887384, 'icd2': 0.00057633076, 'icd3': 1.8391012, 'icd4_train': 0.0062554893, 'icd4_val': 0.004274698, 'icd4_test': 0.0017388349}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1205\n",
            "{'mu': 1.2000000000000002, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.798, 'test_acc': 0.824, 'icd0': tensor(0.1218), 'icd1': 6.7657585, 'icd2': 0.00054768904, 'icd3': 1.8635569, 'icd4_train': 0.0061077476, 'icd4_val': 0.003983166, 'icd4_test': 0.0015627489}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1218\n",
            "{'mu': 1.3, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.722, 'test_acc': 0.747, 'icd0': tensor(0.1197), 'icd1': 7.185792, 'icd2': 0.00064380595, 'icd3': 1.9392071, 'icd4_train': 0.0059391507, 'icd4_val': 0.004931994, 'icd4_test': 0.0017082772}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1197\n",
            "{'mu': 1.4000000000000001, 'seed': None, 'train_acc': 1.0, 'val_acc': 0.688, 'test_acc': 0.717, 'icd0': tensor(0.1211), 'icd1': 7.4784174, 'icd2': 0.00062920357, 'icd3': 1.9968508, 'icd4_train': 0.005951202, 'icd4_val': 0.0048425538, 'icd4_test': 0.0016953939}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1211\n",
            "{'mu': 1.5, 'seed': None, 'train_acc': 0.9786, 'val_acc': 0.504, 'test_acc': 0.504, 'icd0': tensor(0.1211), 'icd1': 7.601456, 'icd2': 0.0004964861, 'icd3': 2.0790493, 'icd4_train': 0.004766128, 'icd4_val': 0.0030666762, 'icd4_test': 0.0011531337}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1211\n",
            "{'mu': 1.6, 'seed': None, 'train_acc': 0.95, 'val_acc': 0.422, 'test_acc': 0.407, 'icd0': tensor(0.1097), 'icd1': 7.7100196, 'icd2': 0.00038655475, 'icd3': 2.1215842, 'icd4_train': 0.0046846853, 'icd4_val': 0.002895407, 'icd4_test': 0.0011904591}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1097\n",
            "{'mu': 1.7000000000000002, 'seed': None, 'train_acc': 0.95, 'val_acc': 0.416, 'test_acc': 0.403, 'icd0': tensor(0.1052), 'icd1': 7.8716407, 'icd2': 0.000399804, 'icd3': 2.142628, 'icd4_train': 0.004797952, 'icd4_val': 0.002928737, 'icd4_test': 0.0012182401}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1052\n",
            "{'mu': 1.8, 'seed': None, 'train_acc': 0.9429, 'val_acc': 0.4, 'test_acc': 0.394, 'icd0': tensor(0.1040), 'icd1': 7.9793324, 'icd2': 0.0004123524, 'icd3': 2.1625235, 'icd4_train': 0.0047558607, 'icd4_val': 0.0029636149, 'icd4_test': 0.0012094908}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1040\n",
            "{'mu': 1.9000000000000001, 'seed': None, 'train_acc': 0.9429, 'val_acc': 0.392, 'test_acc': 0.392, 'icd0': tensor(0.1034), 'icd1': 8.08516, 'icd2': 0.00041697614, 'icd3': 2.1789262, 'icd4_train': 0.004818544, 'icd4_val': 0.0029748108, 'icd4_test': 0.0012315282}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1034\n",
            "{'mu': 2.0, 'seed': None, 'train_acc': 0.9143, 'val_acc': 0.376, 'test_acc': 0.375, 'icd0': tensor(0.1026), 'icd1': 8.1682005, 'icd2': 0.0004162058, 'icd3': 2.197521, 'icd4_train': 0.004765302, 'icd4_val': 0.0029782355, 'icd4_test': 0.0012611471}\n",
            "classes: [0 1 2 3 4 5 6]\n",
            "    Icd: 0.1026\n"
          ]
        }
      ],
      "source": [
        "# train and evaluate \n",
        "Results, params, params_tag, reg_loss, metrics  = evaluation(mus=mus, reg_loss=reg_loss, p_reg_phi = p_reg_phi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "UJld5MfBl72W",
        "outputId": "3231dad0-f303-41be-d73a-03ed1324739b"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/reproducing_abdul/IntraClassDistance.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/reproducing_abdul/IntraClassDistance.ipynb#ch0000038?line=0'>1</a>\u001b[0m \u001b[39m# report vis\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/reproducing_abdul/IntraClassDistance.ipynb#ch0000038?line=1'>2</a>\u001b[0m report_vis(Results, params, params_tag, reg_loss)\n",
            "File \u001b[0;32m~/dtu/2021-22-spring/advanced_machine_learning/p-reg/reproducing_abdul/utils.py:226\u001b[0m, in \u001b[0;36mreport_vis\u001b[0;34m(Results, params, params_tag, reg_loss)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mfor\u001b[39;00m i_tag,tag \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tags):    \n\u001b[1;32m    225\u001b[0m     \u001b[39mfor\u001b[39;00m i_data,dataset_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(datasets):\n\u001b[0;32m--> 226\u001b[0m       axs[i_tag]\u001b[39m.\u001b[39mplot(\u001b[39msorted\u001b[39m(params),aux_sort(Results[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset_name\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mtag\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m][\u001b[39m1\u001b[39;49m],params), color\u001b[39m=\u001b[39mcolors[i_data], marker\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    227\u001b[0m       axs[i_tag]\u001b[39m.\u001b[39mlegend()\n\u001b[1;32m    228\u001b[0m       axs[i_tag]\u001b[39m.\u001b[39mset_title(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mtitles[i_tag]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x432 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# report vis\n",
        "report_vis(Results, params, params_tag, reg_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xBscuZN_41q",
        "outputId": "b7b64dc1-233e-44d7-d951-13031e4271fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= Cora:\n",
            "    acc best Mus on test: 0.8\n",
            "    icd best Mus on test: 0.0\n",
            "========= CiteSeer:\n",
            "    acc best Mus on test: 0.5\n",
            "    icd best Mus on test: 0.2\n",
            "========= PubMed:\n",
            "    acc best Mus on test: 0.2\n",
            "    icd best Mus on test: 0.0\n"
          ]
        }
      ],
      "source": [
        "# report stats\n",
        "report_stats(Results, params, params_tag)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "IntraClassDistance.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('p-reg-env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "19b21e06a3ecf92dacb2d0dce038f81bb705746e8008c815c25552dc2d0953db"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
