Systematic training
Lets start with a single dataset - cora
Possible parameters:
Mu (always test with mu=0 as well to be able to compare to no preg used)
Different loss functions (in preg and not only in preg)
splits
number of nodes applied with P-reg
Number of layers
Model architecture


Outputs:
Txt or csv with
Parameters
Metrics
Train accuracy
Val accuracy
Test accuracy
Roc-auc
Reproducibility!!


Visualizations
Figure 2 stuff- i.e. effect of different parameter values
Figure 3 stuff - i.e. tfne visualizations

Implement laplacian regularization

Implement different metrics (or just find them in different packages)

Tables

Implementing new regularization
Hand in learning objectives




First experiment session:

Parameters to test:
Fix dataset = cora
Fix loss = [L_cls = crossentropy, L_preg = cressentropy]
Fix model architecture
Fix model hyperparameters
Fix num_epochs=100

Mu
Splits
Unmask preg ratio


Outputs:
Parameters of training session
Train accuracy
Test accuracy
Code execution time

Sample output:

Dataset, L_cls, L_preg, model, hyperparameters, mu, train_size, valid_size, unmask_preg_ratio

“Cora”, “ce”, “ce”, “GCN0”, “num_node_features=1433, num_classes=7, 1, 10, 5, 0.5
“Cora”, “ce”, “ce”, “GCN0”, “num_node_features=1433, num_classes=7, 1, 20, 10, 0.5
“Cora”, “ce”, “ce”, “GCN0”, “num_node_features=1433, num_classes=7, 1, 10, 5, 0.8




