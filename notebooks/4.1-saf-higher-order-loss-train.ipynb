{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg\n",
      "Obtaining file:///home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: src\n",
      "  Attempting uninstall: src\n",
      "    Found existing installation: src 0.1.0\n",
      "    Uninstalling src-0.1.0:\n",
      "      Successfully uninstalled src-0.1.0\n",
      "  Running setup.py develop for src\n",
      "Successfully installed src-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from src.models.dense import NN0\n",
    "from src.models.dense import NN1\n",
    "from src.models.gcn import GCN0\n",
    "\n",
    "from src.models.train_model import train_with_loss\n",
    "from src.models.train_model import random_splits\n",
    "\n",
    "from src.models.reg import make_preg_loss\n",
    "\n",
    "from src.models.reg import compute_a_hat\n",
    "\n",
    "from src.models.evaluate_model import evaluate0\n",
    "from src.models.evaluate_model import evaluate1\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from src.models.evaluate_model import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "train size: 350\n",
      "valid size: 140\n",
      "test size: 2218\n",
      "-------------------------------------------------------------\n",
      "mu: 0.0, train_acc: 0.9943, val_acc: 0.8429, test_acc: 0.8354\n",
      "-------------------------------------------------------------\n",
      "mu: 0.05, train_acc: 0.9943, val_acc: 0.8429, test_acc: 0.8381\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000002?line=44'>45</a>\u001b[0m loss_fn \u001b[39m=\u001b[39m make_preg_loss(L_cls, L_preg, mu, A_hat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000002?line=46'>47</a>\u001b[0m gcn_model \u001b[39m=\u001b[39m GCN0(num_node_features\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mnum_node_features,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000002?line=47'>48</a>\u001b[0m                  num_classes\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mnum_classes) \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000002?line=48'>49</a>\u001b[0m                 \u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000002?line=50'>51</a>\u001b[0m gcn_model \u001b[39m=\u001b[39m train_with_loss(gcn_model, data, loss_fn, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m350\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000002?line=51'>52</a>\u001b[0m \u001b[39m# gcn_model = train2(gcn_model, data)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000002?line=52'>53</a>\u001b[0m acc \u001b[39m=\u001b[39m evaluate0(gcn_model, data)\n",
      "File \u001b[0;32m~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py:101\u001b[0m, in \u001b[0;36mtrain_with_loss\u001b[0;34m(model, data, loss_fn, lr, weight_decay, num_epochs, beta)\u001b[0m\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=96'>97</a>\u001b[0m     Z \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=98'>99</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(data, Z)\n\u001b[0;32m--> <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=100'>101</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=101'>102</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=103'>104</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=T.NormalizeFeatures())\n",
    "# no normalization, using n != 0 and m!= 0 instead\n",
    "# doesnt work, just use normalization instead\n",
    "\n",
    "# try with no normalization, using n != 0 and m!= 0 \n",
    "# dataset = Planetoid(root='data/Planetoid', name='Cora')\n",
    "\n",
    "\n",
    "def set_reg_mask(data, A):\n",
    "    reg_indeces = random.sample(range(data.x.shape[0]), k=A)\n",
    "    reg_mask = torch.zeros(len(data.y), dtype=torch.bool)\n",
    "    for i in reg_indeces:\n",
    "        reg_mask[i] = True\n",
    "    data.reg_mask = reg_mask\n",
    "    return data\n",
    "\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "data = random_splits(data, 50, 20)\n",
    "# data = set_reg_mask(data, data.train_mask.shape[0])\n",
    "data.reg_mask = torch.ones_like(data.train_mask, dtype=torch.bool)\n",
    "\n",
    "L_cls = lambda x, y: F.nll_loss(torch.log(x), y, reduction='sum')\n",
    "L_preg = lambda x, y: F.cross_entropy(x, y, reduction='sum')\n",
    "\n",
    "A_hat = compute_a_hat(data)\n",
    "\n",
    "print('-------------------------------------------------------------')\n",
    "print(f'train size: {data.train_mask.sum()}')\n",
    "print(f'valid size: {data.valid_mask.sum()}')\n",
    "print(f'test size: {data.test_mask.sum()}')\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for mu in range(11):\n",
    "    mu = mu / 10\n",
    "    \n",
    "    torch.manual_seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "    loss_fn = make_preg_loss(L_cls, L_preg, mu, A_hat)\n",
    "\n",
    "    gcn_model = GCN0(num_node_features=dataset.num_node_features,\n",
    "                     num_classes=dataset.num_classes) \\\n",
    "                    .to(device)\n",
    "\n",
    "    gcn_model = train_with_loss(gcn_model, data, loss_fn, num_epochs=350)\n",
    "    # gcn_model = train2(gcn_model, data)\n",
    "    acc = evaluate0(gcn_model, data)\n",
    "    # print(f'mu: {mu}, reg, Accuracy: {acc:.4f}')\n",
    "\n",
    "    train_acc, val_acc, test_acc = evaluate1(gcn_model, data)\n",
    "    metrics.append({'mu': mu, 'train_acc': train_acc, 'val_acc': val_acc, 'test_acc': test_acc})\n",
    "    print(f'mu: {mu}, train_acc: {train_acc:.4f}, val_acc: {val_acc:.4f}, test_acc: {test_acc:.4f}')\n",
    "    print('-------------------------------------------------------------')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.DataFrame(metrics)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df['mu'], df['test_acc'], '-b*')\n",
    "ax.plot(df['mu'], 11*[df['test_acc'][df['mu']==0]], '--b')\n",
    "ax.set(ylim=(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6428)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L_preg = lambda x, y: F.cross_entropy(x, y)\n",
    "\n",
    "x = torch.tensor([\n",
    "    [0,1,1,1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "y = torch.tensor([\n",
    "    [0,1,1,1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "L_preg(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "train size: 350\n",
      "valid size: 140\n",
      "test size: 2218\n",
      "-------------------------------------------------------------\n",
      "mu: 0.0, train_acc: 0.7000, val_acc: 0.6214, test_acc: 0.4892\n",
      "-------------------------------------------------------------\n",
      "mu: 0.1, train_acc: 0.5657, val_acc: 0.5071, test_acc: 0.4391\n",
      "-------------------------------------------------------------\n",
      "mu: 0.2, train_acc: 0.2800, val_acc: 0.2429, test_acc: 0.1614\n",
      "-------------------------------------------------------------\n",
      "mu: 0.3, train_acc: 0.1429, val_acc: 0.1429, test_acc: 0.1028\n",
      "-------------------------------------------------------------\n",
      "mu: 0.4, train_acc: 0.1429, val_acc: 0.1429, test_acc: 0.1028\n",
      "-------------------------------------------------------------\n",
      "mu: 0.5, train_acc: 0.1429, val_acc: 0.1429, test_acc: 0.1028\n",
      "-------------------------------------------------------------\n",
      "mu: 0.6, train_acc: 0.1429, val_acc: 0.1429, test_acc: 0.1028\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000005?line=44'>45</a>\u001b[0m loss_fn \u001b[39m=\u001b[39m make_preg_loss(L_cls, L_preg, mu, A_hat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000005?line=46'>47</a>\u001b[0m gcn_model \u001b[39m=\u001b[39m GCN0(num_node_features\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mnum_node_features,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000005?line=47'>48</a>\u001b[0m                  num_classes\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mnum_classes) \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000005?line=48'>49</a>\u001b[0m                 \u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000005?line=50'>51</a>\u001b[0m gcn_model \u001b[39m=\u001b[39m train_with_loss(gcn_model, data, loss_fn, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m350\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000005?line=51'>52</a>\u001b[0m \u001b[39m# gcn_model = train2(gcn_model, data)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/4.1-saf-higher-order-loss-train.ipynb#ch0000005?line=52'>53</a>\u001b[0m acc \u001b[39m=\u001b[39m evaluate0(gcn_model, data)\n",
      "File \u001b[0;32m~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py:97\u001b[0m, in \u001b[0;36mtrain_with_loss\u001b[0;34m(model, data, loss_fn, lr, weight_decay, num_epochs, beta)\u001b[0m\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=93'>94</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=94'>95</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=96'>97</a>\u001b[0m     Z \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=98'>99</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(data, Z)\n\u001b[1;32m    <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=100'>101</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/gcn.py:15\u001b[0m, in \u001b[0;36mGCN0.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/gcn.py?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/gcn.py?line=12'>13</a>\u001b[0m     x, edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index\n\u001b[0;32m---> <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/gcn.py?line=14'>15</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index)), training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/gcn.py?line=15'>16</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x, edge_index)\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/gcn.py?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:182\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py?line=178'>179</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py?line=179'>180</a>\u001b[0m             edge_index \u001b[39m=\u001b[39m cache\n\u001b[0;32m--> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py?line=181'>182</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin(x)\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py?line=183'>184</a>\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py?line=184'>185</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, edge_weight\u001b[39m=\u001b[39medge_weight,\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py?line=185'>186</a>\u001b[0m                      size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/dense/linear.py:109\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/dense/linear.py?line=106'>107</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/dense/linear.py?line=107'>108</a>\u001b[0m     \u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/nn/dense/linear.py?line=108'>109</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/functional.py?line=1845'>1846</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/functional.py?line=1846'>1847</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[0;32m-> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/nn/functional.py?line=1847'>1848</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=T.NormalizeFeatures())\n",
    "# no normalization, using n != 0 and m!= 0 instead\n",
    "# doesnt work, just use normalization instead\n",
    "\n",
    "# try with no normalization, using n != 0 and m!= 0 \n",
    "# dataset = Planetoid(root='data/Planetoid', name='Cora')\n",
    "\n",
    "\n",
    "def set_reg_mask(data, A):\n",
    "    reg_indeces = random.sample(range(data.x.shape[0]), k=A)\n",
    "    reg_mask = torch.zeros(len(data.y), dtype=torch.bool)\n",
    "    for i in reg_indeces:\n",
    "        reg_mask[i] = True\n",
    "    data.reg_mask = reg_mask\n",
    "    return data\n",
    "\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "data = random_splits(data, 50, 20)\n",
    "# data = set_reg_mask(data, data.train_mask.shape[0])\n",
    "data.reg_mask = torch.ones_like(data.train_mask, dtype=torch.bool)\n",
    "L_cls = lambda x, y: F.cross_entropy(x, y, reduction='sum')\n",
    "L_preg = lambda x, y: F.cross_entropy(x, y, reduction='sum')\n",
    "\n",
    "A_hat = compute_a_hat(data)\n",
    "\n",
    "\n",
    "print('-------------------------------------------------------------')\n",
    "print(f'train size: {data.train_mask.sum()}')\n",
    "print(f'valid size: {data.valid_mask.sum()}')\n",
    "print(f'test size: {data.test_mask.sum()}')\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for mu in range(21):\n",
    "    mu = mu / 10\n",
    "    \n",
    "    torch.manual_seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "    loss_fn = make_preg_loss(L_cls, L_preg, mu, A_hat)\n",
    "\n",
    "    gcn_model = GCN0(num_node_features=dataset.num_node_features,\n",
    "                     num_classes=dataset.num_classes) \\\n",
    "                    .to(device)\n",
    "\n",
    "    gcn_model = train_with_loss(gcn_model, data, loss_fn, num_epochs=350)\n",
    "    # gcn_model = train2(gcn_model, data)\n",
    "    acc = evaluate0(gcn_model, data)\n",
    "    # print(f'mu: {mu}, reg, Accuracy: {acc:.4f}')\n",
    "\n",
    "    train_acc, val_acc, test_acc = evaluate1(gcn_model, data)\n",
    "    metrics.append({'mu': mu, 'train_acc': train_acc, 'val_acc': val_acc, 'test_acc': test_acc})\n",
    "    print(f'mu: {mu}, train_acc: {train_acc:.4f}, val_acc: {val_acc:.4f}, test_acc: {test_acc:.4f}')\n",
    "    print('-------------------------------------------------------------')\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19b21e06a3ecf92dacb2d0dce038f81bb705746e8008c815c25552dc2d0953db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('p-reg-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
