{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg\n",
      "Obtaining file:///home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: src\n",
      "  Attempting uninstall: src\n",
      "    Found existing installation: src 0.1.0\n",
      "    Uninstalling src-0.1.0:\n",
      "      Successfully uninstalled src-0.1.0\n",
      "  Running setup.py develop for src\n",
      "Successfully installed src-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3950)\n",
      "tensor(3.4753)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "P = torch.tensor([\n",
    "    [.1,.4,.1,.2],\n",
    "    [.3,.4,.5,.6],\n",
    "    [.7,.3,.2,.1]\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "Q = torch.tensor([\n",
    "    [.3,.4,.2,.3],\n",
    "    [.4,.5,.6,.1],\n",
    "    [.1,.3,.4,.2]\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "Y = torch.tensor([1,3,0])\n",
    "\n",
    "phi_0 = - (P * torch.log(Q)).sum()\n",
    "phi_1 = F.cross_entropy(P, Y, reduction='sum')\n",
    "\n",
    "print(phi_0)\n",
    "print(phi_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3896)\n",
      "tensor(5.3896)\n",
      "tensor(5.3950)\n"
     ]
    }
   ],
   "source": [
    "P = torch.tensor([\n",
    "    [.1,.4,.1,.2],\n",
    "    [.3,.4,.5,.6],\n",
    "    [.7,.3,.2,.1]\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "Q = torch.tensor([\n",
    "    [.3,.4,.2,.3],\n",
    "    [.4,.5,.6,.1],\n",
    "    [.1,.3,.4,.2]\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "Y = torch.tensor([1,3,0])\n",
    "\n",
    "custome_crossentropy = lambda P, Q: - (P * torch.log(Q)).sum()\n",
    "\n",
    "print(torch.nn.CrossEntropyLoss(reduction='sum')(P,Q))\n",
    "print(torch.nn.functional.cross_entropy(P,Q, reduction='sum'))\n",
    "print(custome_crossentropy(P,Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.9757, grad_fn=<NegBackward0>)\n",
      "tensor(5.2695, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from notebooks.FinalAnalysisAbdul.models import MLP, GCN, GAT\n",
    "from notebooks.FinalAnalysisAbdul.p_reg_loss import A_hat_computations\n",
    "\n",
    "\n",
    "seed = 0\n",
    "\n",
    "# set up torch env and dataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = Planetoid(root=f'data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = GCN(dataset, hidden_channels=16, seed = seed).to(device)\n",
    "\n",
    "_, Z = model(data)\n",
    "\n",
    "L_preg_0 = lambda x, y: - (x * torch.log(y)).sum()\n",
    "L_preg_1 = lambda x, y: F.cross_entropy(x, y, reduction='sum')\n",
    "\n",
    "A_hat, A_hat_mask, N = A_hat_computations(data)\n",
    "data.reg_mask = torch.ones_like(data.train_mask, dtype=torch.bool)\n",
    "\n",
    "P = F.softmax(Z, dim=1)\n",
    "Q = F.softmax(torch.matmul(A_hat, Z), dim=1)\n",
    "\n",
    "print(L_preg_0((P/1000)[data.reg_mask], (Q/1000)[data.reg_mask]))\n",
    "print(L_preg_1((P/1000)[data.reg_mask], (Q/1000)[data.reg_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19b21e06a3ecf92dacb2d0dce038f81bb705746e8008c815c25552dc2d0953db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('p-reg-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
