{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sandor/dtu/2021-22-spring/advanced_machine_learning\n",
      "Obtaining file:///home/sandor/dtu/2021-22-spring/advanced_machine_learning\n",
      "\u001b[31mERROR: file:///home/sandor/dtu/2021-22-spring/advanced_machine_learning does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.models.dense import NN0\n",
    "from src.models.dense import NN1\n",
    "from src.models.gcn import GCN0\n",
    "from src.models.gcn import GCN1\n",
    "from src.models.gcn import GCN_var_2layer\n",
    "\n",
    "from src.models.gcn import GCN_64_node_2layer\n",
    "from src.models.gcn import GCN_64_node_3layer\n",
    "from src.models.gcn import GCN_64_node_4layer\n",
    "\n",
    "\n",
    "\n",
    "from src.models.gat import GAT\n",
    "\n",
    "from src.models.train_model import train_with_loss\n",
    "from src.models.train_model import random_splits\n",
    "\n",
    "from src.models.reg import make_preg_ce_ce\n",
    "from src.models.reg import make_preg_ce_ce_alt\n",
    "from src.models.reg import make_lap_loss_ce\n",
    "\n",
    "from src.models.reg import compute_a_hat\n",
    "\n",
    "from src.models.evaluate_model import evaluate0\n",
    "from src.models.evaluate_model import evaluate1\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from src.models.evaluate_model import test\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92231\n",
      "70519\n",
      "61651\n"
     ]
    }
   ],
   "source": [
    "gcn64_2 = GCN_64_node_2layer()\n",
    "gcn64_3 = GCN_64_node_3layer()\n",
    "gcn64_4 = GCN_64_node_4layer()\n",
    "\n",
    "count_patameters = lambda model: sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_patameters(gcn64_2))\n",
    "print(count_patameters(gcn64_3))\n",
    "print(count_patameters(gcn64_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of GCN_64_node_3layer(\n",
       "  (conv_1): GCNConv(1433, 48)\n",
       "  (conv_2): GCNConv(48, 30)\n",
       "  (conv_3): GCNConv(30, 7)\n",
       ")>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn64_3.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=T.NormalizeFeatures())\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "A_hat = compute_a_hat(data)\n",
    "\n",
    "data.reg_mask = torch.ones_like(data.train_mask, dtype=torch.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-------------------------------------------------------------')\n",
    "print(f'train size: {data.train_mask.sum()}')\n",
    "print(f'val size: {data.val_mask.sum()}')\n",
    "print(f'test size: {data.test_mask.sum()}')\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "metrics = []\n",
    "for seed in [0,1,2,3,4]:\n",
    "    for hidden_channels in [1, 2, 4, 8, 16, 32, 64, 128]:\n",
    "        for mu in [0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1.]:\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "            loss_fn = make_preg_ce_ce_alt(mu, A_hat)\n",
    "            \n",
    "            model = GCN_var_2layer(hidden_channels)\n",
    "            # model = GCN1(num_node_features=dataset.num_node_features, num_classes=dataset.num_classes)\n",
    "            model = train_with_loss(model, data, loss_fn, num_epochs=200)\n",
    "\n",
    "            acc = evaluate0(model, data)\n",
    "\n",
    "            train_acc, val_acc, test_acc = evaluate1(model, data)\n",
    "            metrics.append({'seed': seed, 'hidden_channels': hidden_channels, 'mu': mu, 'train_acc': np.round(train_acc,4), 'val_acc': np.round(val_acc,4), 'test_acc': np.round(test_acc,4)})\n",
    "            print(metrics[-1])\n",
    "            # print(f'mu: {mu}, train_acc: {train_acc:.4f}, val_acc: {val_acc:.4f}, test_acc: {test_acc:.4f}')\n",
    "            # print('-------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "df.to_csv('reports/figures/hidden_channels_mu.csv')\n",
    "# ridiculously slow implementation, but I don't want to figure this out now\n",
    "arr = np.zeros((df['hidden_channels'].unique().shape[0], df['mu'].unique().shape[0]))\n",
    "for ind_i, i in enumerate(df['hidden_channels'].unique()):\n",
    "    for ind_j, j in enumerate(df['mu'].unique()):\n",
    "        # print((df['hidden_channels'] == i) & (df['mu'] == j))\n",
    "        # print(df[(df['hidden_channels'] == i) & (df['mu'] == j)]['test_acc'])\n",
    "        arr[ind_i,ind_j] = df[(df['hidden_channels'] == i) & (df['mu'] == j)]['test_acc'].mean()\n",
    "# plt.pcolormesh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def add_colorbar(im, fig, ax):\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolormesh([0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1.], [1, 2, 4, 8, 16, 32, 64, 128], arr, )\n",
    "ax.set_yscale('log')\n",
    "ax.set_yticks([1, 2, 4, 8, 16, 32, 64, 128])\n",
    "ax.set_yticklabels([1, 2, 4, 8, 16, 32, 64, 128])\n",
    "add_colorbar(im, fig, ax)\n",
    "ax.set(xlabel='Regularization factor', ylabel='No. neurons in hidden layer')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92231\n",
      "58519\n",
      "46639\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19b21e06a3ecf92dacb2d0dce038f81bb705746e8008c815c25552dc2d0953db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('p-reg-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
