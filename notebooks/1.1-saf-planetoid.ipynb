{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg\n",
      "Obtaining file:///home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: src\n",
      "  Attempting uninstall: src\n",
      "    Found existing installation: src 0.1.0\n",
      "    Uninstalling src-0.1.0:\n",
      "      Successfully uninstalled src-0.1.0\n",
      "  Running setup.py develop for src\n",
      "Successfully installed src-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.dense import NN0\n",
    "from src.models.dense import NN1\n",
    "from src.models.gcn import GCN0\n",
    "\n",
    "from src.models.train_model import train0\n",
    "from src.models.train_model import train1\n",
    "from src.models.train_model import set_masks\n",
    "from src.models.evaluate_model import evaluate0\n",
    "\n",
    "from src.models.utils import random_splits\n",
    "from src.models.utils import propagate\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora')\n",
    "data = dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triaing the model\n",
    "# for A, B in [[5,2], [10,5], [20, 5], [40, 10], [100, 20]]:\n",
    "'''\n",
    "for A, B in [[100, 20]]:\n",
    "    data = random_splits(data, A, B)\n",
    "\n",
    "    gcn_model = GCN0(num_node_features=dataset.num_node_features,\n",
    "                    num_classes=dataset.num_classes) \\\n",
    "                    .to(device)\n",
    "\n",
    "    gcn_model = train0(gcn_model, data)\n",
    "\n",
    "    acc = evaluate0(gcn_model, data)\n",
    "    print(f'Accuracy: {acc:.4f}')\n",
    "'''\n",
    "gcn_model = GCN0(num_node_features=dataset.num_node_features,\n",
    "                    num_classes=dataset.num_classes) \\\n",
    "                    .to(device)\n",
    "\n",
    "gcn_model = train0(gcn_model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[data.train_mask].numpy().tolist().count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([140, 7])\n",
      "L_reg:\t0.012919319793581963\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def reg_loss(p, t, train_mask, A_hat, mu=0.2, phi='ce'):\n",
    "    \"\"\"\n",
    "    Regularization loss\n",
    "    float tensor[N,C] p: predictions on the entire dataset\n",
    "    int tensor[M] t: list of ground-truth class indeces for the training nodes\n",
    "    bool tensor[N] train_mask: bool map for selecting the training nodes from the entire dataset\n",
    "    bool tensor A_hat[N, N]: adjacency matrix for the entire dataset\n",
    "    float mu: regularization factor\n",
    "    \"\"\"\n",
    "\n",
    "    L_1 = F.cross_entropy(p[train_mask], t)\n",
    "\n",
    "    if phi == 'ce':\n",
    "        L_2 = F.cross_entropy(p, A_hat@p)\n",
    "    elif phi == 'l2':\n",
    "        L_2 = F.mse_loss(p, A_hat@p)\n",
    "    elif phi == 'kld':\n",
    "        L_2 = F.kl_div(p, A_hat@p)\n",
    "    else:\n",
    "        raise ValueError('phi must be one of ce (cross_entropy), l2 (squared error) or kld (kullback-leibler divergence)')\n",
    "\n",
    "    \n",
    "    M = train_mask.sum()\n",
    "    N = train_mask.shape[0]\n",
    "\n",
    "    return 1 / M * L_1 + mu / N * L_2\n",
    "\n",
    "gcn_model = GCN0(num_node_features=dataset.num_node_features,\n",
    "                 num_classes=dataset.num_classes) \\\n",
    "                .to(device)\n",
    "\n",
    "\n",
    "def compute_a(data):\n",
    "    a = torch.zeros(data.x.shape[0], data.x.shape[0])\n",
    "\n",
    "    for i in data.edge_index.T:\n",
    "        a[i[0], i[1]] = 1\n",
    "\n",
    "    return a\n",
    "\n",
    "A = compute_a(data)\n",
    "D = torch.diag(A.sum(dim=0))\n",
    "A_hat = D.inverse()@A\n",
    "\n",
    "out = gcn_model(data)\n",
    "print(out[data.train_mask].shape)\n",
    "\n",
    "loss = reg_loss(\n",
    "        p=out, # we make predictions on the entire dataset\n",
    "        t=data.y[data.train_mask], # we assume to have ground-truth labels on only a subset of the dataset\n",
    "        train_mask=data.train_mask, # hence, we also provide the train_mask, to know what nodes have labels\n",
    "        A_hat=A_hat, \n",
    "        mu=0.1)\n",
    "\n",
    "print(f'L_reg:\\t{loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2411,  0.3631, -0.3540, -0.4631, -0.5300],\n",
      "        [ 1.8125, -0.0092,  1.9766, -0.9801, -0.7131],\n",
      "        [ 0.7288, -0.1569, -0.3306,  1.7782, -0.5467]], requires_grad=True)\n",
      "tensor([1, 3, 3])\n",
      "tensor(1.8032, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n.backward()\\n# Example of target with class probabilities\\ninput = torch.randn(3, 5, requires_grad=True)\\ntarget = torch.randn(3, 5).softmax(dim=1)\\nloss = F.cross_entropy(input, target)\\nloss.backward()\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "loss = F.cross_entropy(input, target)\n",
    "print(input)\n",
    "print(target)\n",
    "print(loss)\n",
    "'''\n",
    ".backward()\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "loss = F.cross_entropy(input, target)\n",
    "loss.backward()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10556/10556 [00:00<00:00, 37999.01it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/1.1-saf-planetoid.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/1.1-saf-planetoid.ipynb#ch0000022?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/1.1-saf-planetoid.ipynb#ch0000022?line=2'>3</a>\u001b[0m gcn_model \u001b[39m=\u001b[39m GCN0(num_node_features\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mnum_node_features,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/1.1-saf-planetoid.ipynb#ch0000022?line=3'>4</a>\u001b[0m                  num_classes\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mnum_classes) \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/1.1-saf-planetoid.ipynb#ch0000022?line=4'>5</a>\u001b[0m                 \u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/1.1-saf-planetoid.ipynb#ch0000022?line=6'>7</a>\u001b[0m gcn_model \u001b[39m=\u001b[39m train1(gcn_model, data)\n",
      "File \u001b[0;32m~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py:40\u001b[0m, in \u001b[0;36mtrain1\u001b[0;34m(model, data, lr, weight_decay, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=32'>33</a>\u001b[0m     out \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=33'>34</a>\u001b[0m     loss \u001b[39m=\u001b[39m reg_loss(out[data\u001b[39m.\u001b[39mtrain_mask], \n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=34'>35</a>\u001b[0m           data\u001b[39m.\u001b[39my[data\u001b[39m.\u001b[39mtrain_mask], \n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=35'>36</a>\u001b[0m           M\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mtrain_mask\u001b[39m.\u001b[39msum(), \n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=36'>37</a>\u001b[0m           N \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mtrain_mask\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=37'>38</a>\u001b[0m           A_hat\u001b[39m=\u001b[39mA_hat[data\u001b[39m.\u001b[39mtrain_mask]\u001b[39m.\u001b[39mT[data\u001b[39m.\u001b[39mtrain_mask], \n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=38'>39</a>\u001b[0m           mu\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=39'>40</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=40'>41</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=42'>43</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py:150\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=145'>146</a>\u001b[0m inputs \u001b[39m=\u001b[39m (inputs,) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=146'>147</a>\u001b[0m     \u001b[39mtuple\u001b[39m(inputs) \u001b[39mif\u001b[39;00m inputs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mtuple\u001b[39m()\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=148'>149</a>\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[39mlen\u001b[39m(tensors))\n\u001b[0;32m--> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=149'>150</a>\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _make_grads(tensors, grad_tensors_)\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py:51\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m     <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=49'>50</a>\u001b[0m     \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mnumel() \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=50'>51</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=51'>52</a>\u001b[0m     new_grads\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mones_like(out, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format))\n\u001b[1;32m     <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=52'>53</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "# defining vanilla gcn model\n",
    "\n",
    "def train1(model, data, lr=0.01, weight_decay=5e-4, num_epochs=100):\n",
    "    # training the model\n",
    "    A = compute_a(data)\n",
    "    D = torch.diag(A.sum(dim=0))\n",
    "    A_hat = D.inverse()@A\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = reg_loss(out[data.train_mask], \n",
    "              data.y[data.train_mask], \n",
    "              M=data.train_mask.sum(), \n",
    "              N = data.train_mask.shape[0], \n",
    "              A_hat=A_hat[data.train_mask].T[data.train_mask], \n",
    "              mu=1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model # not sure if inplace would work\n",
    "\n",
    "gcn_model = train1(gcn_model, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19b21e06a3ecf92dacb2d0dce038f81bb705746e8008c815c25552dc2d0953db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('p-reg-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
