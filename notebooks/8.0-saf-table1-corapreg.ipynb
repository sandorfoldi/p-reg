{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg\n",
      "Obtaining file:///home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: src\n",
      "  Attempting uninstall: src\n",
      "    Found existing installation: src 0.1.0\n",
      "    Uninstalling src-0.1.0:\n",
      "      Successfully uninstalled src-0.1.0\n",
      "  Running setup.py develop for src\n",
      "Successfully installed src-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.models.gcn import GCN_var_2layer\n",
    "from src.models.gat import GAT\n",
    "\n",
    "from src.models.train_model import train_with_loss\n",
    "from src.models.train_model import random_splits\n",
    "\n",
    "from src.models.reg import make_preg_ce_ce\n",
    "from src.models.reg import make_preg_ce_ce_alt\n",
    "from src.models.reg import make_lap_loss_ce\n",
    "\n",
    "from src.models.reg import compute_a_hat\n",
    "\n",
    "from src.models.evaluate_model import evaluate0\n",
    "from src.models.evaluate_model import evaluate1\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from src.models.evaluate_model import test\n",
    "from tqdm import tqdm\n",
    "\n",
    "from notebooks.FinalAnalysisAbdul.random_split import random_split as abdul_random_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data = dataset[0].to(device)\\ndata = random_splits(data, 20, 30)\\ndata.reg_mask = torch.ones_like(data.train_mask, dtype=torch.bool)\\nA_hat = compute_a_hat(data)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset_cora = Planetoid(root='data/Planetoid', name='Cora', transform=T.NormalizeFeatures())\n",
    "dataset_citeseer = Planetoid(root='data/Planetoid', name='CiteSeer', transform=T.NormalizeFeatures())\n",
    "dataset_pubmed = Planetoid(root='data/Planetoid', name='PubMed', transform=T.NormalizeFeatures())\n",
    "\n",
    "\"\"\"data = dataset[0].to(device)\n",
    "data = random_splits(data, 20, 30)\n",
    "data.reg_mask = torch.ones_like(data.train_mask, dtype=torch.bool)\n",
    "A_hat = compute_a_hat(data)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/8.0-saf-table1-corapreg.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/8.0-saf-table1-corapreg.ipynb#ch0000003?line=4'>5</a>\u001b[0m random\u001b[39m.\u001b[39mseed(seed)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/8.0-saf-table1-corapreg.ipynb#ch0000003?line=6'>7</a>\u001b[0m data \u001b[39m=\u001b[39m dataset[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/8.0-saf-table1-corapreg.ipynb#ch0000003?line=7'>8</a>\u001b[0m data \u001b[39m=\u001b[39m abdul_random_splits(data, \u001b[39m20\u001b[39;49m, \u001b[39m30\u001b[39;49m, seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/8.0-saf-table1-corapreg.ipynb#ch0000003?line=8'>9</a>\u001b[0m data\u001b[39m.\u001b[39mreg_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones_like(data\u001b[39m.\u001b[39mtrain_mask, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbool)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/8.0-saf-table1-corapreg.ipynb#ch0000003?line=9'>10</a>\u001b[0m A_hat \u001b[39m=\u001b[39m compute_a_hat(data)\n",
      "File \u001b[0;32m~/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/FinalAnalysisAbdul/random_split.py:21\u001b[0m, in \u001b[0;36mrandom_split\u001b[0;34m(dataset, A, B, seed)\u001b[0m\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/FinalAnalysisAbdul/random_split.py?line=18'>19</a>\u001b[0m \u001b[39m# Shuffle y\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/FinalAnalysisAbdul/random_split.py?line=19'>20</a>\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m---> <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/FinalAnalysisAbdul/random_split.py?line=20'>21</a>\u001b[0m y \u001b[39m=\u001b[39m dataset[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39my\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/FinalAnalysisAbdul/random_split.py?line=21'>22</a>\u001b[0m y \u001b[39m=\u001b[39m y[torch\u001b[39m.\u001b[39mrandperm(\u001b[39mlen\u001b[39m(y))]\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/FinalAnalysisAbdul/random_split.py?line=23'>24</a>\u001b[0m \u001b[39m# Assert inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/data/data.py:371\u001b[0m, in \u001b[0;36mData.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/data/data.py?line=369'>370</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/data/data.py?line=370'>371</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_store[key]\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/data/storage.py:68\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/data/storage.py?line=66'>67</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch_geometric/data/storage.py?line=67'>68</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for dataset in [dataset_citeseer, dataset_pubmed]:\n",
    "    for seed in [0,1,2,3,4]:\n",
    "        for model_name in ['gat_preg', 'gcn_vanilla', 'gcn_preg', 'gat_vanilla']:\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "            data = dataset[0].to(device)\n",
    "            data = abdul_random_splits(data, 20, 30, seed=seed)\n",
    "            data.reg_mask = torch.ones_like(data.train_mask, dtype=torch.bool)\n",
    "            A_hat = compute_a_hat(data)\n",
    "\n",
    "            if model_name == 'gcn_vanilla':\n",
    "                loss_fn = make_preg_ce_ce_alt(0, A_hat)    \n",
    "                model = GCN_var_2layer(hidden_channels=64)\n",
    "\n",
    "            elif model_name == 'gcn_preg':\n",
    "                loss_fn = make_preg_ce_ce_alt(0.7, A_hat)    \n",
    "                model = GCN_var_2layer(hidden_channels=64)\n",
    "\n",
    "            elif model_name == 'gat_vanilla':\n",
    "                loss_fn = make_preg_ce_ce_alt(0, A_hat)    \n",
    "                model = GAT(dataset)\n",
    "\n",
    "            elif model_name == 'gat_preg':\n",
    "                loss_fn = make_preg_ce_ce_alt(0.6, A_hat)    \n",
    "                model = GAT(dataset)\n",
    "\n",
    "            else:\n",
    "                raise Exception\n",
    "            model = train_with_loss(model, data, loss_fn, num_epochs=200)\n",
    "\n",
    "            acc = evaluate0(model, data)\n",
    "\n",
    "            train_acc, val_acc, test_acc = evaluate1(model, data)\n",
    "            metrics.append({'model_name': model_name, 'seed': seed,  'train_acc': np.round(train_acc,4), 'val_acc': np.round(val_acc,4), 'test_acc': np.round(test_acc,4)})\n",
    "            print(metrics[-1])\n",
    "            # print(f'mu: {mu}, train_acc: {train_acc:.4f}, val_acc: {val_acc:.4f}, test_acc: {test_acc:.4f}')\n",
    "            # print('-------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_1 = []\n",
    "for dataset in [dataset_cora]:\n",
    "    for seed in [0,1,2,3,4]:\n",
    "        for model_name in ['gcn_vanilla', 'gcn_preg']:\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "            data = dataset[0].to(device)\n",
    "            data = random_splits(data, 20, 30)\n",
    "            data.reg_mask = torch.ones_like(data.train_mask, dtype=torch.bool)\n",
    "            A_hat = compute_a_hat(data)\n",
    "\n",
    "            if model_name == 'gcn_vanilla':\n",
    "                loss_fn = make_preg_ce_ce_alt(0, A_hat)    \n",
    "                model = GCN_var_2layer(hidden_channels=64)\n",
    "\n",
    "            elif model_name == 'gcn_preg':\n",
    "                loss_fn = make_preg_ce_ce_alt(0.7, A_hat)    \n",
    "                model = GCN_var_2layer(hidden_channels=64)\n",
    "\n",
    "            elif model_name == 'gat_vanilla':\n",
    "                loss_fn = make_preg_ce_ce_alt(0, A_hat)    \n",
    "                model = GAT(dataset)\n",
    "\n",
    "            elif model_name == 'gat_preg':\n",
    "                loss_fn = make_preg_ce_ce_alt(0.6, A_hat)    \n",
    "                model = GAT(dataset)\n",
    "\n",
    "            else:\n",
    "                raise Exception\n",
    "            model = train_with_loss(model, data, loss_fn, num_epochs=200)\n",
    "\n",
    "            acc = evaluate0(model, data)\n",
    "\n",
    "            train_acc, val_acc, test_acc = evaluate1(model, data)\n",
    "            metrics_1.append({'model_name': model_name, 'seed': seed,  'train_acc': np.round(train_acc,4), 'val_acc': np.round(val_acc,4), 'test_acc': np.round(test_acc,4)})\n",
    "            print(metrics_1[-1])\n",
    "            # print(f'mu: {mu}, train_acc: {train_acc:.4f}, val_acc: {val_acc:.4f}, test_acc: {test_acc:.4f}')\n",
    "            # print('-------------------------------------------------------------')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19b21e06a3ecf92dacb2d0dce038f81bb705746e8008c815c25552dc2d0953db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('p-reg-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
