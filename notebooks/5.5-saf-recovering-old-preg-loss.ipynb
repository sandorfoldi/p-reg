{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg\n",
      "Obtaining file:///home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: src\n",
      "  Attempting uninstall: src\n",
      "    Found existing installation: src 0.1.0\n",
      "    Uninstalling src-0.1.0:\n",
      "      Successfully uninstalled src-0.1.0\n",
      "  Running setup.py develop for src\n",
      "Successfully installed src-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models.train_model import train_with_loss\n",
    "from src.models.train_model import random_splits\n",
    "\n",
    "from src.models.gcn import GCN_fix_2layer\n",
    "\n",
    "from src.models.reg import make_preg_ce_ce\n",
    "from src.models.reg import make_preg_ce_ce_alt\n",
    "from src.models.reg import make_preg_loss\n",
    "from src.models.reg import make_abduls_preg_loss\n",
    "from src.models.reg import make_lap_loss_ce\n",
    "from src.models.reg import compute_a_hat\n",
    "\n",
    "from src.models.evaluate_model import evaluate1\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=T.NormalizeFeatures())\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "A_hat = compute_a_hat(data)\n",
    "\n",
    "# data = random_splits(data, 50, 20)\n",
    "data.reg_mask = torch.ones_like(data.train_mask, dtype=torch.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "train size: 140\n",
      "val size: 500\n",
      "test size: 1000\n",
      "-------------------------------------------------------------\n",
      "{'mu': 0, 'train_acc': 0.8286, 'val_acc': 0.59, 'test_acc': 0.575}\n",
      "{'mu': 0.1, 'train_acc': 0.5714, 'val_acc': 0.426, 'test_acc': 0.409}\n",
      "{'mu': 0.2, 'train_acc': 0.2857, 'val_acc': 0.114, 'test_acc': 0.133}\n",
      "{'mu': 0.3, 'train_acc': 0.1429, 'val_acc': 0.058, 'test_acc': 0.064}\n",
      "{'mu': 0.4, 'train_acc': 0.1429, 'val_acc': 0.072, 'test_acc': 0.091}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/5.5-saf-recovering-old-preg-loss.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/5.5-saf-recovering-old-preg-loss.ipynb#ch0000003?line=13'>14</a>\u001b[0m loss_fn \u001b[39m=\u001b[39m make_preg_loss(L_cls, L_preg, mu, A_hat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/5.5-saf-recovering-old-preg-loss.ipynb#ch0000003?line=15'>16</a>\u001b[0m model \u001b[39m=\u001b[39m GCN_fix_2layer()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/5.5-saf-recovering-old-preg-loss.ipynb#ch0000003?line=17'>18</a>\u001b[0m model \u001b[39m=\u001b[39m train_with_loss(model, data, loss_fn, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/5.5-saf-recovering-old-preg-loss.ipynb#ch0000003?line=19'>20</a>\u001b[0m train_acc, val_acc, test_acc \u001b[39m=\u001b[39m evaluate1(model, data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sandor/dtu/2021-22-spring/advanced_machine_learning/p-reg/notebooks/5.5-saf-recovering-old-preg-loss.ipynb#ch0000003?line=20'>21</a>\u001b[0m metrics\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mmu\u001b[39m\u001b[39m'\u001b[39m: mu, \u001b[39m'\u001b[39m\u001b[39mtrain_acc\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mround(train_acc,\u001b[39m4\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mround(val_acc,\u001b[39m4\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mtest_acc\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mround(test_acc,\u001b[39m4\u001b[39m)})\n",
      "File \u001b[0;32m~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py:101\u001b[0m, in \u001b[0;36mtrain_with_loss\u001b[0;34m(model, data, loss_fn, lr, weight_decay, num_epochs, beta)\u001b[0m\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=96'>97</a>\u001b[0m     Z \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=98'>99</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(data, Z)\n\u001b[0;32m--> <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=100'>101</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=101'>102</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    <a href='file:///~/dtu/2021-22-spring/advanced_machine_learning/p-reg/src/models/train_model.py?line=103'>104</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///~/.virtualenv/p-reg-env/lib/python3.8/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('-------------------------------------------------------------')\n",
    "print(f'train size: {data.train_mask.sum()}')\n",
    "print(f'val size: {data.val_mask.sum()}')\n",
    "print(f'test size: {data.test_mask.sum()}')\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for mu in [0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1.]:\n",
    "    torch.manual_seed(1)\n",
    "    random.seed(1)\n",
    "    L_cls = lambda x, y: F.cross_entropy(x, y, reduction='sum')\n",
    "    L_preg = lambda x, y: F.cross_entropy(x, y, reduction='sum')\n",
    "    loss_fn = make_preg_loss(L_cls, L_preg, mu, A_hat)\n",
    "    \n",
    "    model = GCN_fix_2layer()\n",
    "\n",
    "    model = train_with_loss(model, data, loss_fn, num_epochs=200)\n",
    "\n",
    "    train_acc, val_acc, test_acc = evaluate1(model, data)\n",
    "    metrics.append({'mu': mu, 'train_acc': np.round(train_acc,4), 'val_acc': np.round(val_acc,4), 'test_acc': np.round(test_acc,4)})\n",
    "    print(metrics[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19b21e06a3ecf92dacb2d0dce038f81bb705746e8008c815c25552dc2d0953db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('p-reg-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
